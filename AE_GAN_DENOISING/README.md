# ğŸ§¼ Image Denoising báº±ng Autoencoder & GAN

## ğŸ“‹ Má»¤C Lá»¤C
1. [Giá»›i thiá»‡u dá»± Ã¡n](#giá»›i-thiá»‡u-dá»±-Ã¡n)
2. [CÃ´ng nghá»‡ sá»­ dá»¥ng](#cÃ´ng-nghá»‡-sá»­-dá»¥ng)
3. [Kiáº¿n trÃºc 2 model](#kiáº¿n-trÃºc-2-model)
4. [Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u](#quy-trÃ¬nh-xá»­-lÃ½-dá»¯-liá»‡u)
5. [Chi tiáº¿t quÃ¡ trÃ¬nh huáº¥n luyá»‡n](#chi-tiáº¿t-quÃ¡-trÃ¬nh-huáº¥n-luyá»‡n)
6. [HÆ°á»›ng dáº«n cháº¡y code](#hÆ°á»›ng-dáº«n-cháº¡y-code)
7. [Káº¿t quáº£ & ÄÃ¡nh giÃ¡](#káº¿t-quáº£--Ä‘Ã¡nh-giÃ¡)

---

## ğŸ¯ Giá»›i Thiá»‡u Dá»± Ãn

### Má»¥c Ä‘Ã­ch
Dá»± Ã¡n nÃ y phÃ¡t triá»ƒn **2 mÃ´ hÃ¬nh Deep Learning** Ä‘á»ƒ **khá»­ nhiá»…u áº£nh (Image Denoising)**:
- **Autoencoder**: MÃ´ hÃ¬nh neural network khÃ´ng giÃ¡m sÃ¡t
- **GAN (Generative Adversarial Network)**: MÃ´ hÃ¬nh sinh vá»›i 2 network cáº¡nh tranh

### BÃ i toÃ¡n
- **Äáº§u vÃ o**: áº¢nh bá»‹ nhiá»…u (Gaussian, Bernoulli, Poisson)
- **Äáº§u ra**: áº¢nh sáº¡ch (khá»­ nhiá»…u)
- **Metrics**: PSNR (Peak Signal-to-Noise Ratio), MSE (Mean Squared Error)

### So sÃ¡nh 2 Model

| TiÃªu chÃ­ | Autoencoder | GAN |
|----------|-------------|-----|
| **Kiáº¿n trÃºc** | 1 network (Encoder + Decoder) | 2 networks (Generator + Discriminator) |
| **Loss function** | MSE/L1 Loss | Adversarial + Reconstruction Loss |
| **Äáº·c Ä‘iá»ƒm** | TÃ¡i táº¡o áº£nh trÆ¡n mÆ°á»£t | áº¢nh sinh sá»‘ng Ä‘á»™ng, chi tiáº¿t tá»‘t |
| **Tá»‘c Ä‘á»™ training** | Nhanh | Cháº­m hÆ¡n (2 networks) |
| **á»¨ng dá»¥ng** | Compression, Anomaly Detection | High-quality denoising |

---

## ğŸ’¾ CÃ´ng Nghá»‡ Sá»­ Dá»¥ng

### Framework & Libraries
```
PyTorch 2.0+           # Deep Learning framework
torchvision            # Bá»™ cÃ´ng cá»¥ xá»­ lÃ½ áº£nh

```

### GPU Optimization
- **CUDA & cuDNN**: Tá»‘i Æ°u hoÃ¡ tÃ­nh toÃ¡n trÃªn GPU
- **Mixed Precision (FP16)**: Giáº£m memory, tÄƒng tá»‘c Ä‘á»™
- **Batch size Ä‘á»™ng**: Tá»± Ä‘iá»u chá»‰nh theo GPU available
- **Non-blocking GPU transfer**: Data transfer song song

### Nhiá»…u Há»— Trá»£
1. **Gaussian (Normal) Noise**: $I_{noisy} = I + \sigma \cdot N(0,1)$
2. **Bernoulli (Dropout) Noise**: Random pixels bá»‹ xÃ³a
3. **Poisson Noise**: Photon noise trong áº£nh thá»±c

---

## ğŸ—ï¸ Kiáº¿n TrÃºc 2 Model

### 1ï¸âƒ£ Autoencoder Architecture

```
INPUT (3Ã—128Ã—128)
    â†“
ENCODER (Downsampling):
  Conv2d(3â†’32, stride=2) + BatchNorm + ReLU     â†’ 32Ã—64Ã—64
  Conv2d(32â†’64, stride=2) + BatchNorm + ReLU    â†’ 64Ã—32Ã—32
  Conv2d(64â†’128, stride=2) + BatchNorm + ReLU   â†’ 128Ã—16Ã—16
  Conv2d(128â†’256, stride=2) + BatchNorm + ReLU  â†’ 256Ã—8Ã—8
    â†“
BOTTLENECK (Compressed Code)
  Dimension: 256Ã—8Ã—8 = 16,384 values
    â†“
DECODER (Upsampling):
  ConvTranspose2d(256â†’128, stride=2) + BatchNorm + ReLU  â†’ 128Ã—16Ã—16
  ConvTranspose2d(128â†’64, stride=2) + BatchNorm + ReLU   â†’ 64Ã—32Ã—32
  ConvTranspose2d(64â†’32, stride=2) + BatchNorm + ReLU    â†’ 32Ã—64Ã—64
  ConvTranspose2d(32â†’3, stride=2) + Sigmoid              â†’ 3Ã—128Ã—128
    â†“
OUTPUT (3Ã—128Ã—128) - áº¢nh khÃ´i phá»¥c
```

**ThÃ´ng sá»‘:**
- **Sá»‘ tham sá»‘**: ~2.1M
- **Compression ratio**: ~150x (3Ã—128Ã—128 â†’ 256Ã—8Ã—8)
- **Loss function**: MSE hoáº·c L1
- **Activation cuá»‘i**: Sigmoid (output: [0, 1])

### 2ï¸âƒ£ GAN Architecture

#### Generator (Sinh áº£nh)
```
INPUT: Random noise z ~ N(0, 1)
  Dimension: [batch, 100]
    â†“
Fully Connected + Reshape â†’ [batch, 256, 8, 8]
    â†“
ConvTranspose2d(256â†’128, stride=2) + BatchNorm + ReLU  â†’ 128Ã—16Ã—16
ConvTranspose2d(128â†’64, stride=2) + BatchNorm + ReLU   â†’ 64Ã—32Ã—32
ConvTranspose2d(64â†’32, stride=2) + BatchNorm + ReLU    â†’ 32Ã—64Ã—64
ConvTranspose2d(32â†’3, stride=2) + Sigmoid              â†’ 3Ã—128Ã—128
    â†“
OUTPUT: Fake image (táº¡o tá»« noise)
```

#### Discriminator (PhÃ¢n biá»‡t thá»±c/giáº£)
```
INPUT: áº¢nh real hoáº·c fake [batch, 3, 128, 128]
    â†“
Conv2d(3â†’64, stride=2) + LeakyReLU(0.2)                â†’ 64Ã—64Ã—64
Conv2d(64â†’128, stride=2) + BatchNorm + LeakyReLU(0.2)  â†’ 128Ã—32Ã—32
Conv2d(128â†’256, stride=2) + BatchNorm + LeakyReLU(0.2) â†’ 256Ã—16Ã—16
Conv2d(256â†’512, stride=2) + BatchNorm + LeakyReLU(0.2) â†’ 512Ã—8Ã—8
    â†“
Adaptive Avg Pool + Flatten â†’ [batch, 512]
    â†“
Linear(512 â†’ 1) + Sigmoid â†’ [batch, 1] âˆˆ [0, 1]
    â†“
OUTPUT: Probability (real=1, fake=0)
```

**ThÃ´ng sá»‘:**
- **Generator param**: ~1.7M
- **Discriminator param**: ~2.5M
- **Total**: ~4.2M

---

## ğŸ“Š Quy TrÃ¬nh Xá»­ LÃ½ Dá»¯ Liá»‡u

### Cáº¥u trÃºc Input
```
Input Dataset/
â”œâ”€â”€ classA/          # Lá»›p A: áº¢nh ngÆ°á»i hoáº·c váº­t thá»ƒ
â”‚   â”œâ”€â”€ image1.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ classB/          # Lá»›p B: áº¢nh ná»n hoáº·c lá»›p khÃ¡c
â”‚   â”œâ”€â”€ image1.png
â”‚   â””â”€â”€ ...
```

**Dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n hoÃ¡:**
1. **Resize**: Táº¥t cáº£ áº£nh â†’ 128Ã—128
2. **ToTensor**: Convert sang tensor [0, 1]
3. **Train/Val split**: 80% train, 20% validation

### QuÃ¡ trÃ¬nh ThÃªm Nhiá»…u
```
Original Image I
    â†“
Add Noise (loai_nhieu, do_manh_nhieu)
    â”œâ”€â”€ Gaussian: I_noisy = I + ÏƒÂ·N(0,1)
    â”œâ”€â”€ Bernoulli: I_noisy = I Â· Bernoulli(p)
    â””â”€â”€ Poisson: I_noisy = Poisson(IÂ·Î»)/Î»
    â†“
Noisy Image I_noisy (training input)
```


## ğŸ“ˆ Káº¿t Quáº£ & ÄÃ¡nh GiÃ¡

### Metrics ÄÃ¡nh GiÃ¡

**PSNR (Peak Signal-to-Noise Ratio)** - Cao hÆ¡n tá»‘t hÆ¡n
$$\text{PSNR} = 20 \log_{10}\left(\frac{255}{\sqrt{\text{MSE}}}\right) \text{ dB}$$

**MSE (Mean Squared Error)** - Tháº¥p hÆ¡n tá»‘t hÆ¡n
$$\text{MSE} = \frac{1}{N}\sum_{i=1}^{N}(I_i - \hat{I}_i)^2$$

### Káº¿t Quáº£ Dá»± Kiáº¿n

| Model | PSNR (dB) | MSE | Loss |
|-------|-----------|-----|------|
| Input (nhiá»…u) | ~15-20 | ~0.02-0.05 | N/A |
| Autoencoder | ~25-30 | ~0.001-0.003 | 0.0245 |
| GAN | ~26-32 | ~0.0008-0.0025 | Balanced |

### Káº¿t Luáº­n
- **Autoencoder**: Nhanh, á»•n Ä‘á»‹nh, áº£nh má»‹n
- **GAN**: áº¢nh sáº¯c nÃ©t, chi tiáº¿t tá»‘t, nhÆ°ng khÃ³ huáº¥n luyá»‡n

---

## ğŸ¨ Visualization Outputs

### 1. Training History (comparison_training.png)
- G Loss, D Loss qua epochs
- PSNR, MSE so sÃ¡nh AE vs GAN

### 2. Denoising Results (ae_vs_gan_comparison.png)
- 4 hÃ ng, má»—i hÃ ng: noisy â†’ clean â†’ AE result â†’ GAN result
- PSNR in dB trÃªn má»—i káº¿t quáº£

### 3. Model Checkpoints
```
best_ae_model.pth           # Best Autoencoder weights
best_gan_generator.pth      # Best Generator weights
best_gan_discriminator.pth  # Best Discriminator weights
```

---

## ğŸ’¡ á»¨ng Dá»¥ng Thá»±c Táº¿

1. **Medical Imaging**: Khá»­ nhiá»…u tá»« CT, MRI scans
2. **Astronomy**: Xá»­ lÃ½ áº£nh tá»« kÃ­nh thiÃªn vÄƒn
3. **Surveillance**: Cáº£i thiá»‡n cháº¥t lÆ°á»£ng video giÃ¡m sÃ¡t
4. **Photography**: Post-processing Ä‘á»ƒ táº¡o áº£nh sáº¡ch hÆ¡n
5. **Data Augmentation**: Sinh áº£nh sáº¡ch tá»« áº£nh nhiá»…u
6. **Anomaly Detection** (AE): PhÃ¡t hiá»‡n báº¥t thÆ°á»ng dá»±a trÃªn reconstruction error

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

1. **Autoencoder**: Hinton & Salakhutdinov (2006) - "Reducing the Dimensionality of Data with Neural Networks"
2. **GAN**: Goodfellow et al. (2014) - "Generative Adversarial Nets"
3. **DCGAN**: Radford et al. (2015) - "Unsupervised Representation Learning with DCGANs"
4. **PyTorch**: https://pytorch.org/docs/
5. **Image Denoising**: https://en.wikipedia.org/wiki/Image_noise

---
