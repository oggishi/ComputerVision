# üßº Image Denoising b·∫±ng Autoencoder & GAN

## üìã M·ª§C L·ª§C
1. [Gi·ªõi thi·ªáu d·ª± √°n](#gi·ªõi-thi·ªáu-d·ª±-√°n)
2. [C√¥ng ngh·ªá s·ª≠ d·ª•ng](#c√¥ng-ngh·ªá-s·ª≠-d·ª•ng)
3. [Ki·∫øn tr√∫c 2 model](#ki·∫øn-tr√∫c-2-model)
4. [Quy tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu](#quy-tr√¨nh-x·ª≠-l√Ω-d·ªØ-li·ªáu)
5. [Chi ti·∫øt qu√° tr√¨nh hu·∫•n luy·ªán](#chi-ti·∫øt-qu√°-tr√¨nh-hu·∫•n-luy·ªán)
6. [H∆∞·ªõng d·∫´n ch·∫°y code](#h∆∞·ªõng-d·∫´n-ch·∫°y-code)
7. [K·∫øt qu·∫£ & ƒê√°nh gi√°](#k·∫øt-qu·∫£--ƒë√°nh-gi√°)

---

## üéØ Gi·ªõi Thi·ªáu D·ª± √Ån

### M·ª•c ƒë√≠ch
D·ª± √°n n√†y ph√°t tri·ªÉn **2 m√¥ h√¨nh Deep Learning** ƒë·ªÉ **kh·ª≠ nhi·ªÖu ·∫£nh (Image Denoising)**:
- **Autoencoder**: M√¥ h√¨nh neural network kh√¥ng gi√°m s√°t
- **GAN (Generative Adversarial Network)**: M√¥ h√¨nh sinh v·ªõi 2 network c·∫°nh tranh

### B√†i to√°n
- **ƒê·∫ßu v√†o**: ·∫¢nh b·ªã nhi·ªÖu (Gaussian, Bernoulli, Poisson)
- **ƒê·∫ßu ra**: ·∫¢nh s·∫°ch (kh·ª≠ nhi·ªÖu)
- **Metrics**: PSNR (Peak Signal-to-Noise Ratio), MSE (Mean Squared Error)

### So s√°nh 2 Model

| Ti√™u ch√≠ | Autoencoder | GAN |
|----------|-------------|-----|
| **Ki·∫øn tr√∫c** | 1 network (Encoder + Decoder) | 2 networks (Generator + Discriminator) |
| **Loss function** | MSE/L1 Loss | Adversarial + Reconstruction Loss |
| **ƒê·∫∑c ƒëi·ªÉm** | T√°i t·∫°o ·∫£nh tr∆°n m∆∞·ª£t | ·∫¢nh sinh s·ªëng ƒë·ªông, chi ti·∫øt t·ªët |
| **T·ªëc ƒë·ªô training** | Nhanh | Ch·∫≠m h∆°n (2 networks) |
| **·ª®ng d·ª•ng** | Compression, Anomaly Detection | High-quality denoising |

---

## üíæ C√¥ng Ngh·ªá S·ª≠ D·ª•ng

### Framework & Libraries
```
PyTorch 2.0+           # Deep Learning framework
torchvision            # B·ªô c√¥ng c·ª• x·ª≠ l√Ω ·∫£nh
torch.cuda.amp         # Mixed Precision Training (GPU optimization)
numpy / matplotlib     # X·ª≠ l√Ω s·ªë & visualize
```

### GPU Optimization
- **CUDA & cuDNN**: T·ªëi ∆∞u ho√° t√≠nh to√°n tr√™n GPU
- **Mixed Precision (FP16)**: Gi·∫£m memory, tƒÉng t·ªëc ƒë·ªô
- **Batch size ƒë·ªông**: T·ª± ƒëi·ªÅu ch·ªânh theo GPU available
- **Non-blocking GPU transfer**: Data transfer song song

### Nhi·ªÖu H·ªó Tr·ª£
1. **Gaussian (Normal) Noise**: $I_{noisy} = I + \sigma \cdot N(0,1)$
2. **Bernoulli (Dropout) Noise**: Random pixels b·ªã x√≥a
3. **Poisson Noise**: Photon noise trong ·∫£nh th·ª±c

---

## üèóÔ∏è Ki·∫øn Tr√∫c 2 Model

### 1Ô∏è‚É£ Autoencoder Architecture

```
INPUT (3√ó128√ó128)
    ‚Üì
ENCODER (Downsampling):
  Conv2d(3‚Üí32, stride=2) + BatchNorm + ReLU     ‚Üí 32√ó64√ó64
  Conv2d(32‚Üí64, stride=2) + BatchNorm + ReLU    ‚Üí 64√ó32√ó32
  Conv2d(64‚Üí128, stride=2) + BatchNorm + ReLU   ‚Üí 128√ó16√ó16
  Conv2d(128‚Üí256, stride=2) + BatchNorm + ReLU  ‚Üí 256√ó8√ó8
    ‚Üì
BOTTLENECK (Compressed Code)
  Dimension: 256√ó8√ó8 = 16,384 values
    ‚Üì
DECODER (Upsampling):
  ConvTranspose2d(256‚Üí128, stride=2) + BatchNorm + ReLU  ‚Üí 128√ó16√ó16
  ConvTranspose2d(128‚Üí64, stride=2) + BatchNorm + ReLU   ‚Üí 64√ó32√ó32
  ConvTranspose2d(64‚Üí32, stride=2) + BatchNorm + ReLU    ‚Üí 32√ó64√ó64
  ConvTranspose2d(32‚Üí3, stride=2) + Sigmoid              ‚Üí 3√ó128√ó128
    ‚Üì
OUTPUT (3√ó128√ó128) - ·∫¢nh kh√¥i ph·ª•c
```

**Th√¥ng s·ªë:**
- **S·ªë tham s·ªë**: ~2.1M
- **Compression ratio**: ~150x (3√ó128√ó128 ‚Üí 256√ó8√ó8)
- **Loss function**: MSE ho·∫∑c L1
- **Activation cu·ªëi**: Sigmoid (output: [0, 1])

### 2Ô∏è‚É£ GAN Architecture

#### Generator (Sinh ·∫£nh)
```
INPUT: Random noise z ~ N(0, 1)
  Dimension: [batch, 100]
    ‚Üì
Fully Connected + Reshape ‚Üí [batch, 256, 8, 8]
    ‚Üì
ConvTranspose2d(256‚Üí128, stride=2) + BatchNorm + ReLU  ‚Üí 128√ó16√ó16
ConvTranspose2d(128‚Üí64, stride=2) + BatchNorm + ReLU   ‚Üí 64√ó32√ó32
ConvTranspose2d(64‚Üí32, stride=2) + BatchNorm + ReLU    ‚Üí 32√ó64√ó64
ConvTranspose2d(32‚Üí3, stride=2) + Sigmoid              ‚Üí 3√ó128√ó128
    ‚Üì
OUTPUT: Fake image (t·∫°o t·ª´ noise)
```

#### Discriminator (Ph√¢n bi·ªát th·ª±c/gi·∫£)
```
INPUT: ·∫¢nh real ho·∫∑c fake [batch, 3, 128, 128]
    ‚Üì
Conv2d(3‚Üí64, stride=2) + LeakyReLU(0.2)                ‚Üí 64√ó64√ó64
Conv2d(64‚Üí128, stride=2) + BatchNorm + LeakyReLU(0.2)  ‚Üí 128√ó32√ó32
Conv2d(128‚Üí256, stride=2) + BatchNorm + LeakyReLU(0.2) ‚Üí 256√ó16√ó16
Conv2d(256‚Üí512, stride=2) + BatchNorm + LeakyReLU(0.2) ‚Üí 512√ó8√ó8
    ‚Üì
Adaptive Avg Pool + Flatten ‚Üí [batch, 512]
    ‚Üì
Linear(512 ‚Üí 1) + Sigmoid ‚Üí [batch, 1] ‚àà [0, 1]
    ‚Üì
OUTPUT: Probability (real=1, fake=0)
```

**Th√¥ng s·ªë:**
- **Generator param**: ~1.7M
- **Discriminator param**: ~2.5M
- **Total**: ~4.2M

---

## üìä Quy Tr√¨nh X·ª≠ L√Ω D·ªØ Li·ªáu

### C·∫•u tr√∫c Input
```
Input Dataset/
‚îú‚îÄ‚îÄ classA/          # L·ªõp A: ·∫¢nh ng∆∞·ªùi ho·∫∑c v·∫≠t th·ªÉ
‚îÇ   ‚îú‚îÄ‚îÄ image1.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ classB/          # L·ªõp B: ·∫¢nh n·ªÅn ho·∫∑c l·ªõp kh√°c
‚îÇ   ‚îú‚îÄ‚îÄ image1.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

**D·ªØ li·ªáu ƒë∆∞·ª£c chu·∫©n ho√°:**
1. **Resize**: T·∫•t c·∫£ ·∫£nh ‚Üí 128√ó128
2. **ToTensor**: Convert sang tensor [0, 1]
3. **Train/Val split**: 80% train, 20% validation

### Qu√° tr√¨nh Th√™m Nhi·ªÖu
```
Original Image I
    ‚Üì
Add Noise (loai_nhieu, do_manh_nhieu)
    ‚îú‚îÄ‚îÄ Gaussian: I_noisy = I + œÉ¬∑N(0,1)
    ‚îú‚îÄ‚îÄ Bernoulli: I_noisy = I ¬∑ Bernoulli(p)
    ‚îî‚îÄ‚îÄ Poisson: I_noisy = Poisson(I¬∑Œª)/Œª
    ‚Üì
Noisy Image I_noisy (training input)
```

### Data Loading
```python
# C·∫•u h√¨nh t·ªëi ∆∞u GPU
batch_size = 32          # GPU c√≥ ƒë·ªß VRAM
num_workers = 4          # Parallel loading
pin_memory = True        # Transfer nhanh h∆°n
```

---

## üéì Chi Ti·∫øt Qu√° Tr√¨nh Hu·∫•n Luy·ªán

### Autoencoder Training

**Target Function:**
$$L_{AE} = \text{MSE}(\hat{I}, I_{target})$$

V·ªõi:
- $\hat{I}$: ·∫¢nh t√°i t·∫°o t·ª´ encoder-decoder
- $I_{target}$: ·∫¢nh g·ªëc (ho·∫∑c ·∫£nh g·ªëc/nhi·ªÖu t√πy thu·ªôc mode)

**Qu√° tr√¨nh:**
```
Epoch 1 - N:
  For each batch:
    1. ƒê·ªçc ·∫£nh s·∫°ch (input)
    2. Th√™m nhi·ªÖu ‚Üí ·∫£nh nhi·ªÖu (noisy input)
    3. Forward: noisy_input ‚Üí Autoencoder ‚Üí reconstructed
    4. T√≠nh loss: MSE(reconstructed, clean_image)
    5. Backward pass + Optimizer step
    
  Validation:
    - T√≠nh PSNR, MSE tr√™n validation set
    - L∆∞u checkpoint n·∫øu PSNR t·ªët nh·∫•t
```

**Hyperparameters:**
```
Epochs: 5
Batch size: 32
Learning rate: 1e-3
Optimizer: Adam
Loss: MSE
Mixed Precision: Enabled (n·∫øu GPU capability >= 7)
```

### GAN Training

**Loss Functions:**

Generator loss:
$$L_G = L_{adv} + \lambda \cdot L_{recon}$$

Discriminator loss:
$$L_D = L_{real} + L_{fake}$$

V·ªõi:
- $L_{adv}$: Adversarial loss (BCEWithLogitsLoss)
- $L_{recon}$: Reconstruction loss (L1)
- $\lambda$: Weight c·ªßa reconstruction (th∆∞·ªùng = 100)

**Qu√° tr√¨nh Training (t·ª´ng iteration):**

```
Step 1: Update Discriminator
  1. ƒê·ªçc batch ·∫£nh s·∫°ch
  2. Th√™m nhi·ªÖu
  
  3. Forward real images ‚Üí D
     Loss_real = D_loss(D(clean), label=1)
  
  4. Forward fake images t·ª´ Generator ‚Üí D
     Loss_fake = D_loss(D(G(noisy)), label=0)
  
  5. Total D loss = Loss_real + Loss_fake
  6. Backward + Optimizer step

Step 2: Update Generator
  1. Forward noisy ‚Üí Generator ‚Üí fake
  
  2. Adversarial loss:
     G_loss_adv = D_loss(D(fake), label=1)
  
  3. Reconstruction loss:
     G_loss_recon = L1(fake, clean)
  
  4. Total G loss = G_loss_adv + 100 * G_loss_recon
  5. Backward + Optimizer step

Validation:
  - T√≠nh PSNR, MSE tr√™n validation set
  - L∆∞u checkpoint n·∫øu PSNR t·ªët nh·∫•t
```

**Hyperparameters:**
```
Epochs: 5
Batch size: 32
Learning rate: 2e-4
Optimizer: Adam (Œ≤1=0.5, Œ≤2=0.999)
Lambda (recon weight): 100.0
Loss: BCEWithLogitsLoss + L1Loss
Mixed Precision: Enabled
```

---

## üöÄ H∆∞·ªõng D·∫´n Ch·∫°y Code

### B∆∞·ªõc 1: Chu·∫©n B·ªã Environment
```bash
# C√†i th∆∞ vi·ªán
pip install torch torchvision
pip install pillow numpy matplotlib

# Ki·ªÉm tra GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### B∆∞·ªõc 2: Chu·∫©n B·ªã D·ªØ Li·ªáu
```
AE_GAN_DENOISING/
‚îú‚îÄ‚îÄ thumbnails/
‚îÇ   ‚îú‚îÄ‚îÄ classA/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img1.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ classB/
‚îÇ       ‚îú‚îÄ‚îÄ img1.png
‚îÇ       ‚îî‚îÄ‚îÄ ...
```

### B∆∞·ªõc 3: Ch·∫°y Notebook

#### Cell 1-4: Setup & Configuration
```python
# Ki·ªÉm tra GPU, thi·∫øt l·∫≠p hyperparameters
# Output: Device info, Model architecture
```

#### Cell 5-6: Prepare Data
```python
# Load ImageFolder dataset
# T·∫°o DataLoaders v·ªõi num_workers t·ªëi ∆∞u
```

#### Cell 7: Evaluate & Visualize Functions
```python
# ƒê·ªãnh nghƒ©a PSNR, MSE, h√†m th√™m nhi·ªÖu
# H√†m l∆∞u ·∫£nh minh ho·∫°
```

#### Cell 8: Train Autoencoder
```python
# Hu·∫•n luy·ªán Autoencoder
# Th·ªùi gian: ~2-3 ph√∫t (GPU)
# L∆∞u: best_ae_model.pth
```

#### Cell 9: Plot Training History
```python
# V·∫Ω bi·ªÉu ƒë·ªì Loss, PSNR, MSE
```

#### Cell 10: Train GAN
```python
# Hu·∫•n luy·ªán Generator + Discriminator
# Th·ªùi gian: ~3-5 ph√∫t (GPU)
# L∆∞u: best_gan_generator.pth, best_gan_discriminator.pth
```

#### Cell 11-12: Comparison & Visualization
```python
# So s√°nh AE vs GAN
# T·∫°o b·∫£ng metrics & visualize k·∫øt qu·∫£
```

### B∆∞·ªõc 4: Xem K·∫øt Qu·∫£
```bash
# Output files ƒë∆∞·ª£c l∆∞u trong:
./outputs_denoise/

# Ho·∫∑c (tr√™n Kaggle):
/kaggle/working/outputs_denoise/

# Files:
- viz_best_autoencoder.png    # K·∫øt qu·∫£ AE
- viz_best_gan_generator.png  # K·∫øt qu·∫£ GAN
- comparison_training.png     # So s√°nh hu·∫•n luy·ªán
- ae_vs_gan_comparison.png    # So s√°nh chi ti·∫øt
```

### X·ª≠ L√Ω L·ªói Th∆∞·ªùng G·∫∑p

| L·ªói | Gi·∫£i ph√°p |
|-----|----------|
| **CUDA out of memory** | Gi·∫£m batch_size: 32 ‚Üí 16 ‚Üí 8 |
| **Dataset not found** | Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n `thu_muc_du_lieu` |
| **Module not found** | Ch·∫°y: `pip install torch torchvision pillow` |
| **Slow training (CPU)** | B·∫≠t GPU ho·∫∑c gi·∫£m s·ªë epoch |

---

## üìà K·∫øt Qu·∫£ & ƒê√°nh Gi√°

### Metrics ƒê√°nh Gi√°

**PSNR (Peak Signal-to-Noise Ratio)** - Cao h∆°n t·ªët h∆°n
$$\text{PSNR} = 20 \log_{10}\left(\frac{255}{\sqrt{\text{MSE}}}\right) \text{ dB}$$

**MSE (Mean Squared Error)** - Th·∫•p h∆°n t·ªët h∆°n
$$\text{MSE} = \frac{1}{N}\sum_{i=1}^{N}(I_i - \hat{I}_i)^2$$

### K·∫øt Qu·∫£ D·ª± Ki·∫øn

| Model | PSNR (dB) | MSE | Loss |
|-------|-----------|-----|------|
| Input (nhi·ªÖu) | ~15-20 | ~0.02-0.05 | N/A |
| Autoencoder | ~25-30 | ~0.001-0.003 | 0.0245 |
| GAN | ~26-32 | ~0.0008-0.0025 | Balanced |

### K·∫øt Lu·∫≠n
- **Autoencoder**: Nhanh, ·ªïn ƒë·ªãnh, ·∫£nh m·ªãn
- **GAN**: ·∫¢nh s·∫Øc n√©t, chi ti·∫øt t·ªët, nh∆∞ng kh√≥ hu·∫•n luy·ªán

---

## üé® Visualization Outputs

### 1. Training History (comparison_training.png)
- G Loss, D Loss qua epochs
- PSNR, MSE so s√°nh AE vs GAN

### 2. Denoising Results (ae_vs_gan_comparison.png)
- 4 h√†ng, m·ªói h√†ng: noisy ‚Üí clean ‚Üí AE result ‚Üí GAN result
- PSNR in dB tr√™n m·ªói k·∫øt qu·∫£

### 3. Model Checkpoints
```
best_ae_model.pth           # Best Autoencoder weights
best_gan_generator.pth      # Best Generator weights
best_gan_discriminator.pth  # Best Discriminator weights
```

---

## üí° ·ª®ng D·ª•ng Th·ª±c T·∫ø

1. **Medical Imaging**: Kh·ª≠ nhi·ªÖu t·ª´ CT, MRI scans
2. **Astronomy**: X·ª≠ l√Ω ·∫£nh t·ª´ k√≠nh thi√™n vƒÉn
3. **Surveillance**: C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng video gi√°m s√°t
4. **Photography**: Post-processing ƒë·ªÉ t·∫°o ·∫£nh s·∫°ch h∆°n
5. **Data Augmentation**: Sinh ·∫£nh s·∫°ch t·ª´ ·∫£nh nhi·ªÖu
6. **Anomaly Detection** (AE): Ph√°t hi·ªán b·∫•t th∆∞·ªùng d·ª±a tr√™n reconstruction error

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

1. **Autoencoder**: Hinton & Salakhutdinov (2006) - "Reducing the Dimensionality of Data with Neural Networks"
2. **GAN**: Goodfellow et al. (2014) - "Generative Adversarial Nets"
3. **DCGAN**: Radford et al. (2015) - "Unsupervised Representation Learning with DCGANs"
4. **PyTorch**: https://pytorch.org/docs/
5. **Image Denoising**: https://en.wikipedia.org/wiki/Image_noise

---

**Author**: Computer Vision Project  
**Date**: December 2025  
**Framework**: PyTorch 2.0+
