# PHÃT HIá»†N NGÆ¯á»œI ÄI Bá»˜ Báº°NG DEEP LEARNING

## ğŸ“‹ Má»¤C Lá»¤C
1. [Giá»›i thiá»‡u dá»± Ã¡n](#giá»›i-thiá»‡u-dá»±-Ã¡n)
2. [Táº­p dá»¯ liá»‡u Penn-Fudan](#táº­p-dá»¯-liá»‡u-penn-fudan)
3. [5 MÃ´ hÃ¬nh Deep Learning](#5-mÃ´-hÃ¬nh-deep-learning)
4. [Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u](#quy-trÃ¬nh-xá»­-lÃ½-dá»¯-liá»‡u)
5. [Chi tiáº¿t cÃ¡c mÃ´ hÃ¬nh](#chi-tiáº¿t-cÃ¡c-mÃ´-hÃ¬nh)
6. [Káº¿t quáº£ vÃ  Visualization](#káº¿t-quáº£-vÃ -visualization)
7. [HÆ°á»›ng dáº«n cháº¡y code](#hÆ°á»›ng-dáº«n-cháº¡y-code)
8. [á»¨ng dá»¥ng thá»±c táº¿](#á»©ng-dá»¥ng-thá»±c-táº¿)

---

## ğŸ¯ Giá»›i thiá»‡u Dá»± Ãn

### Má»¥c Ä‘Ã­ch
Dá»± Ã¡n nÃ y phÃ¡t triá»ƒn **5 mÃ´ hÃ¬nh Deep Learning khÃ¡c nhau** Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n **phÃ¡t hiá»‡n vÃ  phÃ¢n khÃºc ngÆ°á»i Ä‘i bá»™ (Pedestrian Detection & Segmentation)** tá»« hÃ¬nh áº£nh.

### Pháº¡m vi
- **BÃ i toÃ¡n chÃ­nh**: PhÃ¡t hiá»‡n vá»‹ trÃ­ ngÆ°á»i trong áº£nh
- **BÃ i toÃ¡n phá»¥**: PhÃ¢n loáº¡i crops, tÃ¡i táº¡o áº£nh, táº¡o áº£nh 
- **Dataset**: Penn-Fudan Pedestrian Dataset (124 áº£nh huáº¥n luyá»‡n)
- **Framework**: PyTorch + TorchVision

### Tá»•ng quan 5 mÃ´ hÃ¬nh
| MÃ´ hÃ¬nh | Nhiá»‡m vá»¥ | Äáº§u vÃ o | Äáº§u ra | Loáº¡i há»c |
|---------|----------|---------|--------|----------|
| CNN (ResNet18) | PhÃ¢n loáº¡i tá»«ng crop (ngÆ°á»i vs ná»n) | áº¢nh 64Ã—64 | NhÃ£n lá»›p (0: ná»n, 1: ngÆ°á»i) | Supervised |
| Faster R-CNN | PhÃ¡t hiá»‡n vá»‹ trÃ­ & váº½ bounding box | áº¢nh gá»‘c 384Ã—288 | Tá»a Ä‘á»™ bbox + Ä‘á»™ tin cáº­y | Supervised |
| Mask R-CNN | PhÃ¢n khÃºc tá»«ng ngÆ°á»i thÃ nh máº·t náº¡ pixel | áº¢nh gá»‘c 384Ã—288 | Máº·t náº¡ nhá»‹ phÃ¢n + bbox cho má»—i ngÆ°á»i | Supervised |
| AutoEncoder | TÃ¡i táº¡o áº£nh (nÃ©n & giáº£i nÃ©n Ä‘áº·c trÆ°ng) | áº¢nh 64Ã—64 | áº¢nh tÃ¡i táº¡o 64Ã—64 | Unsupervised |
| GAN (DCGAN) | Táº¡o áº£nh ngÆ°á»i giáº£ máº¡o tá»« latent vector | Noise ngáº«u nhiÃªn (100 chiá»u) | áº¢nh tá»•ng há»£p 64Ã—64 giá»‘ng ngÆ°á»i tháº­t | Unsupervised |

---

## ğŸ“Š Táº­p Dá»¯ Liá»‡u Penn-Fudan

### Cáº¥u trÃºc dá»¯ liá»‡u
```
PennFudanPed/
â”œâ”€â”€ PNGImages/          # áº¢nh gá»‘c (384Ã—288 pixels)
â”‚   â”œâ”€â”€ FudanPed00001.png
â”‚   â”œâ”€â”€ FudanPed00002.png
â”‚   â””â”€â”€ ... (74 áº£nh tá»« Fudan)
â”œâ”€â”€ PedMasks/           # Máº·t náº¡ (mask) nhá»‹ phÃ¢n cho má»—i áº£nh
â”‚   â”œâ”€â”€ FudanPed00001_mask.png
â”‚   â”œâ”€â”€ FudanPed00002_mask.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Annotation/         # File vÄƒn báº£n vá»›i tá»a Ä‘á»™ bounding box
â”‚   â”œâ”€â”€ FudanPed00001.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ crops64/            # áº¢nh cáº¯t 64Ã—64 Ä‘Æ°á»£c táº¡o tá»« bounding boxes
    â”œâ”€â”€ FudanPed00001_0.png
    â”œâ”€â”€ FudanPed00001_1.png
    â””â”€â”€ ... (~2000 áº£nh cáº¯t)
```

### ThÃ´ng tin chi tiáº¿t
- **Tá»•ng áº£nh gá»‘c**: 124 áº£nh (74 tá»« Fudan, 50 tá»« Penn)
- **KÃ­ch thÆ°á»›c áº£nh**: 384Ã—288 pixels
- **Sá»‘ lÆ°á»£ng ngÆ°á»i**: ~345 ngÆ°á»i
- **Trung bÃ¬nh/áº£nh**: ~2 ngÆ°á»i
- **Máº·t náº¡**: Má»—i áº£nh cÃ³ 1 file `_mask.png` vá»›i ID cho má»—i ngÆ°á»i
- **PhÃ¢n chia dá»¯ liá»‡u**:
  - Train: 80% (99 áº£nh)
  - Test: 20% (25 áº£nh)

### Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

#### 1. Táº¡o áº¢nh Cáº¯t 64Ã—64
```python
def load_target(mask_p):
    """
    ChuyÃªn Ä‘á»•i file mask thÃ nh:
    - Bounding boxes (tá»a Ä‘á»™ hÃ¬nh chá»¯ nháº­t)
    - Labels (nhÃ£n lá»›p = 1 cho ngÆ°á»i)
    - Masks (máº·t náº¡ nhá»‹ phÃ¢n)
    """
    mask = np.array(Image.open(mask_p))
    obj_ids = np.unique(mask)[1:]  # ID cá»§a má»—i ngÆ°á»i
    
    # Táº¡o máº·t náº¡ nhá»‹ phÃ¢n cho má»—i ngÆ°á»i
    masks = (mask[..., None] == obj_ids).astype(np.uint8).transpose(2,0,1)
    
    # TÃ­nh bounding box tá»« máº·t náº¡
    boxes = []
    for m in masks:
        pos = np.argwhere(m)  # TÃ¬m táº¥t cáº£ pixel = 1
        y1, x1 = pos.min(0)
        y2, x2 = pos.max(0)
        boxes.append([x1, y1, x2, y2])
    
    return boxes, labels, masks
```

#### 2. Cáº¯t áº£nh tá»« Bounding Boxes
```
Quy trÃ¬nh:
  1. Äá»c áº£nh gá»‘c
  2. Láº¥y bounding boxes
  3. Cáº¯t má»—i ngÆ°á»i theo box
  4. Resize thÃ nh 64Ã—64
  5. LÆ°u thÃ nh file PNG riÃªng
  
Káº¿t quáº£: ~2000 áº£nh cáº¯t Ä‘á»ƒ dÃ¹ng cho CNN/AE/GAN
```

---

##  5 MÃ´ HÃ¬nh Deep Learning

### 1ï¸âƒ£ CNN - ResNet18 (PhÃ¢n Loáº¡i)

#### Má»¥c Ä‘Ã­ch
- **PhÃ¢n loáº¡i áº£nh 64Ã—64**: CÃ³ pháº£i ngÆ°á»i hay khÃ´ng?

- Äáº§u ra: 2 lá»›p (person=1, non-person=0)

#### Kiáº¿n trÃºc
```
Input (3Ã—64Ã—64)
    â†“
ResNet18 (pre-trained = False)
    â”œâ”€â”€ Layer 1-4: Residual blocks
    â””â”€â”€ FC layers: 512 â†’ 2 classes
    â†“
Output: Logits [batch_size, 2]
```

#### ThÃ´ng sá»‘
- **Sá»‘ tham sá»‘**: ~11.2M
- **Epoch**: 10
- **Batch size**: 32
- **Optimizer**: Adam (lr=1e-3)
- **Loss**: Cross Entropy Loss
- **Dataset**: 490 train + 123 val
- **Positive samples**: 423
- **Negative samples**: 190

#### Hiá»‡u suáº¥t
```
Epoch 1: val acc=0.293
Epoch 2: val acc=0.496
Epoch 3: val acc=0.959
Epoch 4: val acc=0.919
Epoch 5: val acc=0.943
Epoch 6: val acc=0.967
Epoch 7: val acc=0.959
Epoch 8: val acc=0.984
Epoch 9: val acc=0.984
Epoch 10: val acc=0.967

---
```
### 2ï¸âƒ£ Faster R-CNN (PhÃ¡t Hiá»‡n)

#### Má»¥c Ä‘Ã­ch
- **PhÃ¡t hiá»‡n ngÆ°á»i trong áº£nh gá»‘c**
- Output: Bounding boxes + confidence scores
- Sá»­ dá»¥ng full image khÃ´ng cáº§n cáº¯t

#### Kiáº¿n trÃºc
```
Input (3Ã—HÃ—W)
    â†“
Backbone: ResNet50 + FPN
    â””â”€â”€ Feature pyramid (multi-scale features)
    â†“
Region Proposal Network (RPN)
    â””â”€â”€ Generate ~2000 proposal boxes
    â†“
ROI Pooling
    â””â”€â”€ Extract features tá»« proposal
    â†“
Classification Head
    â”œâ”€â”€ Box predictor (2 classes)
    â””â”€â”€ Bounding box regressor
    â†“
Output: 
  â”œâ”€â”€ Boxes: [N, 4] tá»a Ä‘á»™
  â”œâ”€â”€ Scores: [N] confidence
  â””â”€â”€ Labels: [N] class ID
```

#### ThÃ´ng sá»‘
- **Backbone**: ResNet50 + FPN (Feature Pyramid Network)
- **Sá»‘ tham sá»‘**: ~41.4M
- **Weights**: Pre-trained trÃªn COCO
- **Epoch**: 2
- **Batch size**: 2 (GPU memory constraint)
- **Optimizer**: SGD (lr=0.005, momentum=0.9)
- **Loss**: RPN loss + Classification loss + Box regression loss

#### Hiá»‡u suáº¥t
```

Epoch 1/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:36<00:00,  1.86it/s, loss=0.1450]
âœ… Epoch 1/6 completed in 36.5s | Avg Loss: 17.6114

Epoch 2/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:36<00:00,  1.84it/s, loss=0.1660]
âœ… Epoch 2/6 completed in 37.0s | Avg Loss: 7.6883

Epoch 3/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:37<00:00,  1.82it/s, loss=0.1037]
âœ… Epoch 3/6 completed in 37.3s | Avg Loss: 6.5595

Epoch 4/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:38<00:00,  1.79it/s, loss=0.1058]
âœ… Epoch 4/6 completed in 38.1s | Avg Loss: 5.8970

Epoch 5/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:39<00:00,  1.72it/s, loss=0.0557]
âœ… Epoch 5/6 completed in 39.6s | Avg Loss: 4.3591

Epoch 6/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:40<00:00,  1.70it/s, loss=0.0483]
âœ… Epoch 6/6 completed in 40.0s | Avg Loss: 3.8907
```



### 3ï¸âƒ£ Mask R-CNN (PhÃ¢n KhÃºc)

#### Má»¥c Ä‘Ã­ch
- **Instance segmentation**: PhÃ¡t hiá»‡n + phÃ¢n khÃºc má»—i ngÆ°á»i
- Output: Máº·t náº¡ + bounding boxes
- TÃ­nh toÃ¡n chÃ­nh xÃ¡c hÃ¬nh dáº¡ng má»—i ngÆ°á»i

#### Kiáº¿n trÃºc
```
Input (3Ã—HÃ—W)
    â†“
Backbone: ResNet50 + FPN
    â”œâ”€â”€ Shared feature extraction
    â””â”€â”€ Multi-scale feature maps
    â†“
Region Proposal Network (RPN)
    â””â”€â”€ Generate proposals
    â†“
ROI Align (khÃ´ng pháº£i ROI Pool)
    â””â”€â”€ ChÃ­nh xÃ¡c hÆ¡n cho mask prediction
    â†“
Parallel Heads:
    â”œâ”€â”€ Classification Head â†’ 2 classes
    â”œâ”€â”€ Bounding Box Regressor
    â””â”€â”€ **Mask Head** (NEW!)
         â””â”€â”€ FCN (Fully Convolutional Network)
             â””â”€â”€ Output: [N, 1, 28, 28] mask per class
    â†“
Output:
  â”œâ”€â”€ Boxes: [N, 4]
  â”œâ”€â”€ Scores: [N]
  â”œâ”€â”€ Labels: [N]
  â””â”€â”€ Masks: [N, H, W] nhá»‹ phÃ¢n
```

#### ThÃ´ng sá»‘
- **Sá»‘ tham sá»‘**: ~44.2M
- **Mask Head**: 256 channels, FCN architecture
- **Epoch**: 6
- **Batch size**: 2
- **Optimizer**: SGD (momentum=0.9)

#### Hiá»‡u suáº¥t
Epoch 1/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:42<00:00,  1.61it/s, loss=0.3493]
âœ… Epoch 1/6 completed in 42.3s | Avg Loss: 46.6854

Epoch 2/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:43<00:00,  1.57it/s, loss=0.2328]
âœ… Epoch 2/6 completed in 43.2s | Avg Loss: 21.0259

Epoch 3/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:43<00:00,  1.55it/s, loss=0.2123]
âœ… Epoch 3/6 completed in 43.9s | Avg Loss: 15.8942

Epoch 4/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:43<00:00,  1.56it/s, loss=0.1667]
âœ… Epoch 4/6 completed in 43.7s | Avg Loss: 14.0750

Epoch 5/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:43<00:00,  1.55it/s, loss=0.2101]
âœ… Epoch 5/6 completed in 44.0s | Avg Loss: 12.2623

Epoch 6/6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:44<00:00,  1.53it/s, loss=0.1160]
âœ… Epoch 6/6 completed in 44.6s | Avg Loss: 11.3528


#### KhÃ¡c biá»‡t so vá»›i Faster R-CNN
| TiÃªu chÃ­ | Faster R-CNN | Mask R-CNN |
|----------|--------------|-----------|
| Äáº§u ra | Boxes + Scores | Boxes + Scores + **Masks** |
| ROI Pool | Coarse | Fine (ROI Align) |
| á»¨ng dá»¥ng | Detection | Instance Segmentation |
| Äá»™ phá»©c táº¡p | Tháº¥p | Cao hÆ¡n |

---

### 4ï¸âƒ£ AutoEncoder (TÃ¡i Táº¡o áº¢nh)

#### Má»¥c Ä‘Ã­ch
- **Há»c biá»ƒu diá»…n khÃ´ng giÃ¡m sÃ¡t** tá»« áº£nh 64Ã—64
- **NÃ©n dá»¯ liá»‡u**: Giáº£m tá»« 3Ã—64Ã—64 â†’ 128 (compressed code)
- **PhÃ¡t hiá»‡n báº¥t thÆ°á»ng**: So sÃ¡nh MSE reconstruction
- **Feature extraction**: DÃ¹ng encoder cho downstream tasks

#### Kiáº¿n trÃºc
```
Input (3Ã—64Ã—64)
    â†“
ENCODER:
  Conv2d(3â†’32, kernel=4, stride=2) + ReLU   â†’ 32Ã—32Ã—32
  Conv2d(32â†’64, kernel=4, stride=2) + ReLU  â†’ 64Ã—16Ã—16
  Conv2d(64â†’128, kernel=4, stride=2) + ReLU â†’ 128Ã—8Ã—8
    â†“
Bottleneck (Compressed code)
    â†“
DECODER:
  ConvTranspose2d(128â†’64, kernel=4, stride=2) + ReLU  â†’ 64Ã—16Ã—16
  ConvTranspose2d(64â†’32, kernel=4, stride=2) + ReLU   â†’ 32Ã—32Ã—32
  ConvTranspose2d(32â†’3, kernel=4, stride=2) + Sigmoid â†’ 3Ã—64Ã—64
    â†“
Output (3Ã—64Ã—64) - áº¢nh tÃ¡i táº¡o
```

#### ThÃ´ng sá»‘
- **Sá»‘ tham sá»‘**: ~2.1M (ráº¥t nháº¹)
- **Dimension**: 3Ã—64Ã—64 â†’ 128Ã—8Ã—8 (compression ratio: ~150x)
- **Epoch**: 30
- **Batch size**: 64
- **Optimizer**: Adam (lr=1e-3)
- **Loss**: MSE (Mean Squared Error)

#### Káº¿t quáº£
```
poch  1/30: L1 Loss=0.1251 | Best=0.1251
Epoch  5/30: L1 Loss=0.0426 | Best=0.0426
Epoch 10/30: L1 Loss=0.0328 | Best=0.0328
Epoch 15/30: L1 Loss=0.0314 | Best=0.0310
Epoch 20/30: L1 Loss=0.0300 | Best=0.0276
Epoch 25/30: L1 Loss=0.0304 | Best=0.0274
Epoch 30/30: L1 Loss=0.0254 | Best=0.0245
```

#### á»¨ng dá»¥ng
- **Anomaly Detection**: Náº¿u MSE > threshold â†’ báº¥t thÆ°á»ng
- **Data Compression**: DÃ¹ng encoder Ä‘á»ƒ nÃ©n áº£nh
- **Feature Learning**: Encoder layers lÃ m feature extractor

---

### 5ï¸âƒ£ GAN - DCGAN (Táº¡o áº¢nh Tá»•ng Há»£p)

#### Má»¥c Ä‘Ã­ch
- **Táº¡o áº£nh ngÆ°á»i 64Ã—64 thá»±c táº¿ tá»« noise ngáº«u nhiÃªn**
- **Data augmentation**: Táº¡o training data thÃªm
- **Privacy-preserving**: áº¢nh tá»•ng há»£p thay tháº¿ áº£nh tháº­t
- **Chá»©ng minh há»c khÃ´ng giÃ¡m sÃ¡t**: Generator há»c phÃ¢n phá»‘i dá»¯ liá»‡u

#### Kiáº¿n trÃºc

##### Generator (G)
```
Input: Random noise z ~ N(0,1), shape [batch, 64, 1, 1]
    â†“
ConvTranspose2d(64, 512, kernel=4, stride=1, pad=0) + ReLU  â†’ 512Ã—4Ã—4
ConvTranspose2d(512, 256, kernel=4, stride=2, pad=1) + ReLU â†’ 256Ã—8Ã—8
ConvTranspose2d(256, 128, kernel=4, stride=2, pad=1) + ReLU â†’ 128Ã—16Ã—16
ConvTranspose2d(128, 3, kernel=4, stride=2, pad=1) + Tanh   â†’ 3Ã—64Ã—64
    â†“
Output: Fake image ~ [-1, 1] (Tanh output)
```

##### Discriminator (D)
```
Input: Real/Fake image, shape [batch, 3, 64, 64]
    â†“
Conv2d(3, 64, kernel=4, stride=2, pad=1) + LeakyReLU(0.2)                â†’ 64Ã—32Ã—32
Conv2d(64, 128, kernel=4, stride=2, pad=1) + BatchNorm2d + LeakyReLU     â†’ 128Ã—16Ã—16
Conv2d(128, 256, kernel=4, stride=2, pad=1) + BatchNorm2d + LeakyReLU    â†’ 256Ã—8Ã—8
Conv2d(256, 1, kernel=4, stride=1, pad=0)                                â†’ 1Ã—1Ã—1
    â†“
Output: Logit (Ä‘iá»ƒm thá»±c/giáº£)
```


#### ThÃ´ng sá»‘
- **Generator param**: ~1.7M
- **Discriminator param**: ~1.8M
- **Latent dimension (nz)**: 64
- **Epoch**: 100
- **Batch size**: 64
- **Optimizer**:
  - Generator: Adam (lr=2e-4, beta1=0.5)
  - Discriminator: Adam (lr=2e-4, beta1=0.5)
- **Loss**: BCEWithLogitsLoss

#### Káº¿t quáº£ Huáº¥n Luyá»‡n
```
Epoch   1/100: D Loss=-42.6121 | G Loss=32.3636 | GP=0.2006
Epoch   5/100: D Loss=-82.3951 | G Loss=106.1968 | GP=24.9636
Epoch  10/100: D Loss=-66.7601 | G Loss=79.8856 | GP=22.8528
Epoch  15/100: D Loss=-60.7648 | G Loss=65.7075 | GP=23.0156
Epoch  20/100: D Loss=-58.8079 | G Loss=62.4049 | GP=21.8783
Epoch  25/100: D Loss=-47.9745 | G Loss=33.5453 | GP=16.7308
Epoch  30/100: D Loss=-43.2105 | G Loss=24.1113 | GP=14.5866
Epoch  35/100: D Loss=-42.3529 | G Loss=3.6158 | GP=13.5290
Epoch  40/100: D Loss=-40.2293 | G Loss=-7.4197 | GP=13.2516
Epoch  45/100: D Loss=-35.9524 | G Loss=-9.3946 | GP=12.0025
Epoch  50/100: D Loss=-33.0638 | G Loss=-7.7295 | GP=9.6321
Epoch  55/100: D Loss=-31.4066 | G Loss=8.2952 | GP=9.7162
Epoch  60/100: D Loss=-29.4300 | G Loss=-0.5442 | GP=9.1760
Epoch  65/100: D Loss=-28.4854 | G Loss=-6.4294 | GP=8.4540
Epoch  70/100: D Loss=-25.3650 | G Loss=-13.6383 | GP=7.0295
Epoch  75/100: D Loss=-25.7261 | G Loss=-21.2284 | GP=7.1632
...
Epoch  95/100: D Loss=-23.0451 | G Loss=-19.4365 | GP=5.5377
Epoch 100/100: D Loss=-22.6645 | G Loss=-19.0220 | GP=5.3548

```

#### á»¨ng dá»¥ng
- **Data Augmentation**: Táº¡o thÃªm áº£nh training
- **Privacy**: Táº¡o áº£nh fake thay cho áº£nh tháº­t
- **Simulation**: Táº¡o dataset tá»•ng há»£p

---

## âš™ï¸ Quy TrÃ¬nh Xá»­ LÃ½ Dá»¯ Liá»‡u

### SÆ¡ Ä‘á»“ tá»•ng thá»ƒ
```
1. Load Dataset
   â””â”€â”€ PennFudanPed/
       â”œâ”€â”€ PNGImages/*.png
       â”œâ”€â”€ PedMasks/*_mask.png
       â””â”€â”€ Annotation/*.txt

2. Preprocess
   â”œâ”€â”€ Parse mask â†’ extract boxes, masks, labels
   â””â”€â”€ Create 64Ã—64 crops from bounding boxes

3. Create Dataloaders
   â”œâ”€â”€ CNN Dataset: PedCropDataset (64Ã—64, labels)
   â”œâ”€â”€ Faster R-CNN: PennFudanDet (full image, boxes)
   â”œâ”€â”€ Mask R-CNN: PennFudanSeg (full image, boxes+masks)
   â”œâ”€â”€ AutoEncoder: CropOnly (64Ã—64, no labels)
   â””â”€â”€ GAN: CropOnly (same as AE)

4. Train Models
   â”œâ”€â”€ CNN (3 epochs)
   â”œâ”€â”€ Faster R-CNN (2 epochs)
   â”œâ”€â”€ Mask R-CNN (2 epochs)
   â”œâ”€â”€ AutoEncoder (3 epochs)
   â””â”€â”€ GAN (3 epochs)

5. Generate Visualizations
   â”œâ”€â”€ CNN_Results.png
   â”œâ”€â”€ RCNN_Detection.png
   â”œâ”€â”€ MaskRCNN_Segmentation.png
   â”œâ”€â”€ AE_Reconstruction.png
   â”œâ”€â”€ GAN_Generated.png
   â”œâ”€â”€ DEMO_Full_Pipeline.png
   â”œâ”€â”€ Performance_Analysis.png
   â””â”€â”€ CNN_Feature_Maps.png

6. Analysis
   â””â”€â”€ Compare models, show trade-offs
```

### Custom Collate Function

VÃ¬ batch chá»©a áº£nh kÃ­ch thÆ°á»›c khÃ¡c nhau, cáº§n custom collate:

```python
def collate(batch):
    """
    Batch lÃ  danh sÃ¡ch (img, target) tuples
    Target lÃ  dict vá»›i 'boxes', 'labels', 'masks'
    Return: (list of images, list of targets)
    """
    imgs, targets = zip(*batch)
    return list(imgs), list(targets)
```

**Táº¡i sao cáº§n?** 
- áº¢nh gá»‘c cÃ³ kÃ­ch thÆ°á»›c 384Ã—288, khÃ¡c nhau
- PyTorch batch cáº§n tensor cÃ¹ng kÃ­ch thÆ°á»›c
- Collate function tráº£ vá» list thay vÃ¬ tensor

---

## ğŸ“Š Chi Tiáº¿t CÃ¡c MÃ´ HÃ¬nh

### Tá»•ng Há»£p ThÃ´ng Sá»‘

| TiÃªu chÃ­ | CNN | Faster R-CNN | Mask R-CNN | AE | GAN |
|----------|-----|--------------|-----------|----|----|
| **Nhiá»‡m vá»¥** | PhÃ¢n loáº¡i | PhÃ¡t hiá»‡n | PhÃ¢n khÃºc | TÃ¡i táº¡o | Táº¡o |
| **Äáº§u vÃ o** | 64Ã—64 | Full image | Full image | 64Ã—64 | Noise |
| **Äáº§u ra** | Class label | Boxes | Masks+Boxes | áº¢nh tÃ¡i táº¡o | áº¢nh giáº£ |
| **Sá»‘ tham sá»‘** | 11.2M | 41.4M | 44.2M | 2.1M | 3.5M |
| **Epoch** | 3 | 2 | 2 | 3 | 3 |
| **Accuracy/Loss** | 100% | - | - | MSE: 0.0293 | Balanced |
| **Backbone** | ResNet18 | ResNet50+FPN | ResNet50+FPN | - | - |

### YÃªu Cáº§u TÃ i NguyÃªn

| ThÃ nh pháº§n | YÃªu cáº§u |
|-----------|---------|
| **RAM** | â‰¥8GB (16GB recommended) |
| **GPU** | NVIDIA vá»›i CUDA (hoáº·c CPU cháº­m) |
| **Thá»i gian huáº¥n luyá»‡n** | ~30-40 phÃºt (vá»›i GPU) |
| **Dung lÆ°á»£ng model** | ~200MB (táº¥t cáº£ model) |
| **Dataset size** | ~200MB |

---

## ğŸ¨ Káº¿t Quáº£ vÃ  Visualization

### 1. CNN_Results.png
**Ná»™i dung**: 8 áº£nh cáº¯t 64Ã—64 vÃ  dá»± Ä‘oÃ¡n class
- Cá»™t trÃªn: Original samples
- Cá»™t dÆ°á»›i: CNN predictions
- TiÃªu Ä‘á» xanh: Dá»± Ä‘oÃ¡n Ä‘Ãºng
- TiÃªu Ä‘á» Ä‘á»: Dá»± Ä‘oÃ¡n sai
- **Káº¿t quáº£**: 100% accuracy!

### 2. RCNN_Detection.png
**Ná»™i dung**: 2 áº£nh gá»‘c full size
- **Xanh**: Ground truth boxes
- **Äá» nÃ©t**: Predicted boxes
- **Score**: Confidence score má»—i detection

### 3. MaskRCNN_Segmentation.png
**Ná»™i dung**: 2Ã—2 grid
- **HÃ ng trÃªn**: Ground truth masks (xanh)
- **HÃ ng dÆ°á»›i**: Predicted masks (Ä‘á» nÃ©t)
- **Chiá»u rá»™ng contour**: NhÃ¬n rÃµ ranh giá»›i

### 4. AE_Reconstruction.png
**Ná»™i dung**: 2Ã—8 grid so sÃ¡nh
- **HÃ ng trÃªn**: áº¢nh gá»‘c
- **HÃ ng dÆ°á»›i**: áº¢nh tÃ¡i táº¡o tá»« AE
- **Metrics**: 
  - Average MSE: 0.0293
  - Range: [0.0245, 0.0369]

### 5. GAN_Generated.png
**Ná»™i dung**: 2Ã—8 grid (16 áº£nh giáº£)
- **Táº¥t cáº£**: áº¢nh tá»•ng há»£p tá»« GAN
- **KhÃ´ng cÃ³ labels**: Chá»‰ show áº£nh táº¡o ra
- **Quality**: TÄƒng dáº§n qua epochs

### 6. DEMO_Full_Pipeline.png
**Ná»™i dung**: 3Ã—3 grid (9 panels)
```
Row 1:
  [1] Original Image    [2] GT Mask          [3] GT Boxes
Row 2:
  [4] R-CNN Detections  [5] Mask Segmentation [6] Combined
Row 3:
  [7] CNN Crops         [8] AE Reconstruction [9] GAN Generated
```
**Ã nghÄ©a**: Tá»•ng há»£p táº¥t cáº£ 5 mÃ´ hÃ¬nh trÃªn 1 áº£nh

### 7. Performance_Analysis.png
**Ná»™i dung**: 2Ã—2 charts
- **Top-left**: Model complexity (sá»‘ tham sá»‘)
- **Top-right**: Task capability matrix
- **Bottom-left**: Speed vs Quality trade-off
- **Bottom-right**: Applications & use cases

### 8. CNN_Feature_Maps.png
**Ná»™i dung**: Feature map tá»« CNN layers
- **HÃ ng 1**: Conv layer 1 (32 channels â†’ show 8)
- **HÃ ng 2**: Conv layer 2 (64 channels â†’ show 8)
- **HÃ ng 3**: Conv layer 3 (128 channels â†’ show 8)
- **Colormap**: 'hot' (Ä‘en â†’ Ä‘á»)

---

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y Code

### BÆ°á»›c 1: Setup Environment
```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t
pip install torch torchvision
pip install pillow numpy matplotlib pandas
pip install jupyter  # Náº¿u dÃ¹ng Jupyter

# Kiá»ƒm tra GPU
python -c "import torch; print(torch.cuda.is_available())"
```

### BÆ°á»›c 2: Chuáº©n Bá»‹ Dá»¯ Liá»‡u
```bash
# Download Penn-Fudan Dataset
# Tá»«: http://www.cis.upenn.edu/~jshi/ped_html/

# Giáº£i nÃ©n vÃ o thÆ° má»¥c:
PennFudanPed/
â”œâ”€â”€ PNGImages/
â”œâ”€â”€ PedMasks/
â””â”€â”€ Annotation/
```

### BÆ°á»›c 3: Cáº¥u HÃ¬nh ÄÆ°á»ng Dáº«n
Trong **Cell 1**, sá»­a:
```python
root = r"./PennFudanPed"  # Äá»•i thÃ nh Ä‘Æ°á»ng dáº«n thá»±c táº¿
```

### BÆ°á»›c 4: Cháº¡y tá»«ng Cell

#### Cell 1: Load & Preprocess
```python
# Táº¡o thÆ° má»¥c crops64 tá»« PennFudanPed/
# Káº¿t quáº£: ~2000 áº£nh cáº¯t 64Ã—64
```

#### Cell 2: Train CNN
```python
# Huáº¥n luyá»‡n ResNet18
# Thá»i gian: ~2-3 phÃºt
# Output: model, train_dl_cnn, val_dl_cnn
```

#### Cell 3: Train Faster R-CNN
```python
# Huáº¥n luyá»‡n detection
# Thá»i gian: ~10 phÃºt
# Output: det_model, train_dl_det, val_dl_det
```

#### Cell 4: Train Mask R-CNN
```python
# Huáº¥n luyá»‡n segmentation
# Thá»i gian: ~12 phÃºt
# Output: seg_model, train_dl_seg, val_dl_seg
```

#### Cell 5: Train AutoEncoder
```python
# Huáº¥n luyá»‡n AE
# Thá»i gian: ~3-4 phÃºt
# Output: ae, ae_ds, ae_dl
```

#### Cell 6: Train GAN
```python
# Huáº¥n luyá»‡n DCGAN
# Thá»i gian: ~5-7 phÃºt
# Output: gen, disc
```

#### Cell 7-14: Visualizations
```python
# Cháº¡y láº§n lÆ°á»£t cÃ¡c demo cells
# Táº¡o 8 PNG files
```

### BÆ°á»›c 5: Xem Káº¿t Quáº£
```bash
# Táº¥t cáº£ file PNG lÆ°u trong:
./PennFudanPed/

# Má»Ÿ file:
- CNN_Results.png
- RCNN_Detection.png
- MaskRCNN_Segmentation.png
- AE_Reconstruction.png
- GAN_Generated.png
- DEMO_Full_Pipeline.png
- Performance_Analysis.png
- CNN_Feature_Maps.png
```

### Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p

#### 1. "CUDA out of memory"
```python
# Giáº£m batch size
batch_size = 2 â†’ 1
# Hoáº·c sá»­ dá»¥ng CPU
device = "cpu"
```

#### 2. "Module not found"
```bash
pip install pillow torch torchvision
pip install numpy matplotlib pandas
```

#### 3. Dataset path khÃ´ng tÃ¬m tháº¥y
```python
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
import os
print(os.path.exists(root))
print(os.listdir(root))
```

---

## ğŸ’¡ á»¨ng Dá»¥ng Thá»±c Táº¿

### 1. GiÃ¡m SÃ¡t An ToÃ n (Security)
```
á»¨ng dá»¥ng: PhÃ¡t hiá»‡n ngÆ°á»i trÃ¡i phÃ©p
  â”œâ”€â”€ Faster R-CNN: PhÃ¡t hiá»‡n táº¥t cáº£ ngÆ°á»i
  â”œâ”€â”€ Mask R-CNN: PhÃ¢n khÃºc chÃ­nh xÃ¡c hÃ¬nh dáº¡ng
  â””â”€â”€ Alert: ThÃ´ng bÃ¡o khi cÃ³ ngÆ°á»i á»Ÿ vÃ¹ng cáº¥m
```

### 2. Äáº¿m ÄÃ¡m ÄÃ´ng (Crowd Counting)
```
á»¨ng dá»¥ng: Äáº¿m sá»‘ ngÆ°á»i trong nhÃ  ga, tÃ u Ä‘iá»‡n
  â”œâ”€â”€ Mask R-CNN: Äáº¿m instance tá»« masks
  â”œâ”€â”€ Tá»‘i Æ°u: KhÃ´ng bá»‹ xáº¿p chá»“ng
  â””â”€â”€ Output: Sá»‘ ngÆ°á»i chÃ­nh xÃ¡c
```

### 3. PhÃ¢n TÃ­ch HÃ nh Vi (Behavior Analysis)
```
á»¨ng dá»¥ng: PhÃ¡t hiá»‡n hoáº¡t Ä‘á»™ng báº¥t thÆ°á»ng
  â”œâ”€â”€ CNN: PhÃ¢n loáº¡i tá»«ng ngÆ°á»i
  â”œâ”€â”€ AutoEncoder: PhÃ¡t hiá»‡n anomaly
  â””â”€â”€ Alert: Khi báº¥t thÆ°á»ng Ä‘Æ°á»£c phÃ¡t hiá»‡n
```

### 4. Há»‡ Thá»‘ng Tranh Cáº¥p (Access Control)
```
á»¨ng dá»¥ng: Kiá»ƒm soÃ¡t ra vÃ o cÆ¡ sá»Ÿ
  â”œâ”€â”€ Faster R-CNN: PhÃ¡t hiá»‡n ngÆ°á»i
  â”œâ”€â”€ Mask R-CNN: XÃ¡c Ä‘á»‹nh hÃ¬nh dáº¡ng, tÆ° tháº¿
  â””â”€â”€ Compare: So vá»›i dá»¯ liá»‡u base
```

### 5. Táº¡o Dataset (Data Augmentation)
```
á»¨ng dá»¥ng: Má»Ÿ rá»™ng training data
  â”œâ”€â”€ GAN: Táº¡o áº£nh nhÃ¢n táº¡o
  â”œâ”€â”€ Lá»£i Ã­ch: Báº£o máº­t, Ä‘a dáº¡ng hÃ³a
  â””â”€â”€ Training: DÃ¹ng áº£nh tá»•ng há»£p huáº¥n luyá»‡n
```

### 6. PhÃ¡t Hiá»‡n Báº¥t ThÆ°á»ng (Anomaly)
```
á»¨ng dá»¥ng: TÃ¬m ngÆ°á»i láº¡ hoáº·c hoáº¡t Ä‘á»™ng ká»³ láº¡
  â”œâ”€â”€ AutoEncoder: Há»c pattern bÃ¬nh thÆ°á»ng
  â”œâ”€â”€ MSE Error: Náº¿u cao â†’ báº¥t thÆ°á»ng
  â””â”€â”€ Alert: KÃ­ch hoáº¡t khi vÆ°á»£t threshold
```

### 7. PhÃ¢n TÃ­ch LÆ°u LÆ°á»£ng (Traffic Flow)
```
á»¨ng dá»¥ng: Theo dÃµi luá»“ng ngÆ°á»i di chuyá»ƒn
  â”œâ”€â”€ Mask R-CNN: Theo dÃµi tá»«ng ngÆ°á»i
  â”œâ”€â”€ Temporal tracking: Ghi láº¡i Ä‘Æ°á»ng Ä‘i
  â””â”€â”€ Analytics: Vá»‹ trÃ­, hÆ°á»›ng, tá»‘c Ä‘á»™
```

### 8. Tá»‘i Æ¯u HÃ³a KhÃ´ng Gian (Space Optimization)
```
á»¨ng dá»¥ng: PhÃ¢n bá»‘ con ngÆ°á»i há»£p lÃ½
  â”œâ”€â”€ Crowd counting: Sá»‘ ngÆ°á»i thá»±c táº¿
  â”œâ”€â”€ Heatmap: NÆ¡i táº­p trung
  â””â”€â”€ Decision: Má»Ÿ thÃªm entrance/exit
```

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

1. **Penn-Fudan Dataset**: http://www.cis.upenn.edu/~jshi/ped_html/
2. **Faster R-CNN**: Ren et al., NIPS 2015
3. **Mask R-CNN**: He et al., ICCV 2017
4. **ResNet**: He et al., CVPR 2016
5. **GAN**: Goodfellow et al., NIPS 2014
6. **PyTorch Documentation**: https://pytorch.org/
